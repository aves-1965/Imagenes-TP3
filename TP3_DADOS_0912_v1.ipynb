{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "executionInfo": {
     "elapsed": 9915,
     "status": "ok",
     "timestamp": 1765091698376,
     "user": {
      "displayName": "Elvio Di Prinzio",
      "userId": "07463257976648660716"
     },
     "user_tz": 180
    },
    "id": "Yjty0OzRqVpv",
    "outputId": "2c2ca69f-39b8-41e6-e822-d0ed7ae344ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Etapa 1: Detección de Estabilidad...]\n",
      "   --> REPOSO DETECTADO en el Frame 57\n",
      "\n",
      "[Visualización del Frame Estático 57]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2_imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 166\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[Visualización del Frame Estático \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_idx_estatico\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Mostrar imagen estática (útil para depuración en Colab)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[43mcv2_imshow\u001b[49m(cv2.resize(frame_estatico, (\u001b[32m600\u001b[39m, \u001b[32m400\u001b[39m)))\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# 3. Reconocimiento de Dados (Parte A)\u001b[39;00m\n\u001b[32m    169\u001b[39m dados_detectados_finales = reconocer_dados(frame_estatico.copy())\n",
      "\u001b[31mNameError\u001b[39m: name 'cv2_imshow' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow # Para mostrar imágenes en Colab\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "VIDEO_FILE = 'tirada_1.mp4'\n",
    "UMBRAL_MOVIMIENTO = 5000  # Píxeles de movimiento máximo para considerarse estático\n",
    "FRAMES_ESTABLES = 10      # Número de frames consecutivos para confirmar el reposo\n",
    "\n",
    "# --- FUNCIONES DE PROCESAMIENTO ---\n",
    "\n",
    "def detectar_frames_estaticos(video_path):\n",
    "    \"\"\"Detecta el primer índice de frame donde los dados se detienen.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error al abrir el video: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    prev_gray = None\n",
    "    conteo_estables = 0\n",
    "    frame_idx = 0\n",
    "    frame_estatico_detectado = None\n",
    "\n",
    "    print(\"\\n[Etapa 1: Detección de Estabilidad...]\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        if prev_gray is not None:\n",
    "            # 1. Cálculo de la Diferencia de Frames\n",
    "            frame_delta = cv2.absdiff(prev_gray, gray)\n",
    "            thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "            movimiento_puntos = np.sum(thresh == 255)\n",
    "\n",
    "            if movimiento_puntos < UMBRAL_MOVIMIENTO:\n",
    "                conteo_estables += 1\n",
    "            else:\n",
    "                conteo_estables = 0\n",
    "\n",
    "            # 2. Confirmación de Reposo\n",
    "            if conteo_estables == FRAMES_ESTABLES and frame_estatico_detectado is None:\n",
    "                frame_estatico_detectado = frame_idx - FRAMES_ESTABLES + 1\n",
    "                print(f\"   --> REPOSO DETECTADO en el Frame {frame_estatico_detectado}\")\n",
    "                # Seguimos procesando para llegar al final, pero ya tenemos el índice\n",
    "                # No es necesario salir, pero si el video es largo podría ser óptimo:\n",
    "                # break\n",
    "\n",
    "        prev_gray = gray\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frame_estatico_detectado\n",
    "\n",
    "def reconocer_dados(frame_estatico):\n",
    "    \"\"\"Localiza los dados y cuenta los pips en un frame estático.\"\"\"\n",
    "\n",
    "    # 1. Segmentación de Dados (Filtro por Color Rojo en HSV)\n",
    "    hsv = cv2.cvtColor(frame_estatico, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Rango de Color Rojo (requiere dos rangos en HSV)\n",
    "    mask1 = cv2.inRange(hsv, np.array([0, 100, 100]), np.array([10, 255, 255]))\n",
    "    mask2 = cv2.inRange(hsv, np.array([160, 100, 100]), np.array([180, 255, 255]))\n",
    "    mask_dados = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Mejorar la máscara con Morfología\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask_dados = cv2.dilate(mask_dados, kernel, iterations=2)\n",
    "    mask_dados = cv2.erode(mask_dados, kernel, iterations=1)\n",
    "\n",
    "    # 2. Encontrar contornos de los dados\n",
    "    contornos_dados, _ = cv2.findContours(mask_dados, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    dados_detectados = [] # Lista de ((x, y, w, h), valor)\n",
    "\n",
    "    print(\"\\n[Etapa 2: Reconocimiento de Valor (Pips)]\")\n",
    "\n",
    "    for i, contorno_dado in enumerate(contornos_dados):\n",
    "        area = cv2.contourArea(contorno_dado)\n",
    "        if 1500 < area < 50000: # Ajuste según el tamaño esperado de un dado\n",
    "            x, y, w, h = cv2.boundingRect(contorno_dado)\n",
    "            dado_roi = frame_estatico[y:y+h, x:x+w]\n",
    "\n",
    "            # 3. Contar Pips (Puntos Blancos)\n",
    "            dado_gray = cv2.cvtColor(dado_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Umbralizar para aislar los puntos blancos (pips)\n",
    "            _, mask_pips = cv2.threshold(dado_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Encontrar contornos de los pips\n",
    "            pips_contornos, _ = cv2.findContours(mask_pips, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            valor_dado = 0\n",
    "            for contorno_pip in pips_contornos:\n",
    "                # Filtrar blobs muy pequeños (ruido)\n",
    "                if cv2.contourArea(contorno_pip) > 50:\n",
    "                    valor_dado += 1\n",
    "\n",
    "            dados_detectados.append(((x, y, w, h), valor_dado))\n",
    "            print(f\"   --> Dado {i+1} localizado en ({x},{y}) con valor: {valor_dado}\")\n",
    "\n",
    "    return dados_detectados\n",
    "\n",
    "def generar_video_con_bbox(video_path, frame_idx_inicio_estatico, dados_detectados):\n",
    "    \"\"\"Genera un nuevo video con Bounding Boxes y valores.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return\n",
    "\n",
    "    # Preparar el escritor de video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    ancho = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    alto = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    base_name = video_path.replace(\".mp4\", \"\")\n",
    "    output_filename = f\"{base_name}_anotado.mp4\"\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec para MP4\n",
    "    out = cv2.VideoWriter(output_filename, fourcc, fps, (ancho, alto))\n",
    "\n",
    "    frame_idx = 0\n",
    "    print(f\"\\n[Etapa 3: Generando Video Anotado: {output_filename}]\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Solo aplicar anotaciones cuando los dados están en reposo\n",
    "        if frame_idx >= frame_idx_inicio_estatico:\n",
    "            for i, ((x, y, w, h), valor) in enumerate(dados_detectados):\n",
    "                # Bounding Box (Rectángulo)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 3) # Amarillo\n",
    "\n",
    "                # Etiqueta y Valor (Texto)\n",
    "                etiqueta = f\"Dado {i+1}: {valor}\"\n",
    "                cv2.putText(frame, etiqueta, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    print(f\"   --> ¡Video anotado generado con éxito!\")\n",
    "    out.release()\n",
    "    cap.release()\n",
    "\n",
    "# --- EJECUCIÓN DEL ALGORITMO ---\n",
    "\n",
    "# 1. Detección de Estabilidad\n",
    "frame_idx_estatico = detectar_frames_estaticos(VIDEO_FILE)\n",
    "\n",
    "if frame_idx_estatico is not None:\n",
    "    # 2. Cargar el frame estático\n",
    "    cap = cv2.VideoCapture(VIDEO_FILE)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx_estatico)\n",
    "    ret, frame_estatico = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if ret:\n",
    "        print(f\"\\n[Visualización del Frame Estático {frame_idx_estatico}]\")\n",
    "        # Mostrar imagen estática (útil para depuración en Colab)\n",
    "        cv2_imshow(cv2.resize(frame_estatico, (600, 400)))\n",
    "\n",
    "        # 3. Reconocimiento de Dados (Parte A)\n",
    "        dados_detectados_finales = reconocer_dados(frame_estatico.copy())\n",
    "\n",
    "        # 4. Mostrar Resultados Finales (Parte A)\n",
    "        valores_obtenidos = [valor for _, valor in dados_detectados_finales]\n",
    "        suma_total = sum(valores_obtenidos)\n",
    "\n",
    "        print(\"\\n--- RESULTADOS DE LA TIRADA 1 ---\")\n",
    "        print(f\"Frames Estáticos Confirmados desde el Frame: {frame_idx_estatico}\")\n",
    "        print(f\"Valores obtenidos: {valores_obtenidos}\")\n",
    "        print(f\"Suma Total: {suma_total}\")\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "        # 5. Generar el Video Anotado (Parte B)\n",
    "        generar_video_con_bbox(VIDEO_FILE, frame_idx_estatico, dados_detectados_finales)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: No se pudo leer el frame {frame_idx_estatico}\")\n",
    "else:\n",
    "    print(f\"\\nResultado: No se detectaron frames estáticos en {VIDEO_FILE}.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
